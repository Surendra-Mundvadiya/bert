{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        'context': 'The sky is blue and the grass is green.',\n",
    "        'question': 'What color is the sky?',\n",
    "        'answer': 'blue'\n",
    "    },\n",
    "    {\n",
    "        'context': 'The sky is blue and the grass is green.',\n",
    "        'question': 'What color is the sky?',\n",
    "        'answer': 'blue'\n",
    "    },\n",
    "    # Add more question-answer pairs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your data\n",
    "inputs = [tokenizer(qa['question'], qa['context'], truncation=True,\n",
    "                    padding='max_length', max_length=512) for qa in data]\n",
    "answers = [qa['answer'] for qa in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into torch tensors\n",
    "for input in inputs:\n",
    "    for key in input:\n",
    "        input[key] = torch.tensor(input[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get start and end positions of answers\n",
    "for input, answer in zip(inputs, answers):\n",
    "    start = input['input_ids'].tolist().index(\n",
    "        tokenizer.encode(answer, add_special_tokens=False)[0])\n",
    "    end = start + len(tokenizer.encode(answer, add_special_tokens=False)) - 1\n",
    "    input['start_positions'] = torch.tensor(start)\n",
    "    input['end_positions'] = torch.tensor(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for your data\n",
    "dataloader = DataLoader(inputs, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a basic training loop\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 6.332866668701172\n",
      "Epoch 2 Loss 6.167593002319336\n",
      "Epoch 3 Loss 5.922531604766846\n",
      "Epoch 4 Loss 5.587536811828613\n",
      "Epoch 5 Loss 5.358992099761963\n",
      "Epoch 6 Loss 5.095773220062256\n",
      "Epoch 7 Loss 4.771237373352051\n",
      "Epoch 8 Loss 4.642463684082031\n",
      "Epoch 9 Loss 4.518061637878418\n",
      "Epoch 10 Loss 4.051026344299316\n",
      "Epoch 11 Loss 3.873443603515625\n",
      "Epoch 12 Loss 3.8055920600891113\n",
      "Epoch 13 Loss 3.318305492401123\n",
      "Epoch 14 Loss 3.12795352935791\n",
      "Epoch 15 Loss 2.925119161605835\n",
      "Epoch 16 Loss 2.6708922386169434\n",
      "Epoch 17 Loss 2.5038745403289795\n",
      "Epoch 18 Loss 2.259643077850342\n",
      "Epoch 19 Loss 2.055074691772461\n",
      "Epoch 20 Loss 1.8324575424194336\n",
      "Epoch 21 Loss 1.6323204040527344\n",
      "Epoch 22 Loss 1.4868766069412231\n",
      "Epoch 23 Loss 1.3070985078811646\n",
      "Epoch 24 Loss 1.1371068954467773\n",
      "Epoch 25 Loss 0.8396139144897461\n",
      "Epoch 26 Loss 0.7627565264701843\n",
      "Epoch 27 Loss 0.7226934432983398\n",
      "Epoch 28 Loss 0.6475984454154968\n",
      "Epoch 29 Loss 0.5844744443893433\n",
      "Epoch 30 Loss 0.4695398509502411\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):  # Train for 3 epochs\n",
    "    for batch in dataloader:\n",
    "        # Move batch to device\n",
    "        for key in batch:\n",
    "            batch[key] = batch[key].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Epoch {epoch+1} Loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('my_qa_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"The sky is blue and the grass is green.\"\n",
    "question = \"What color is the grass?\"\n",
    "\n",
    "# Prepare the question and the context for the model\n",
    "inputs = tokenizer(question, context, return_tensors='pt')\n",
    "\n",
    "# Run the model\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most probable start and end tokens\n",
    "answer_start = torch.argmax(outputs.start_logits)\n",
    "answer_end = torch.argmax(outputs.end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "answer = tokenizer.convert_tokens_to_string(\n",
    "    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  blue\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer: \", answer) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
